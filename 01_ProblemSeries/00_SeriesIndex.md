# Decision Behavior Governance Series — Index

This series examines why contemporary AI governance fails—not because policies are missing, but because **decisions are delegated to AI systems without explicit boundaries, traceability, or evidence**.

When decision-making moves from humans to probabilistic systems, governance cannot remain a post-hoc auditing function. It must enter engineering itself.

This series establishes the **problem definition** for Decision Behavior Governance.

---

## Articles in this Series

1. **The Ceiling of Prompts: Why LLM-Based Engineering Has Reached a Structural Limit**  
    Examines why prompt-based control reaches an inherent ceiling as system complexity grows.
2. **Efficiency Amplification and Responsibility Displacement in AI-Assisted Engineering**  
    Explores how AI-driven productivity gains displace responsibility rather than eliminate it.
3. **Before We Talk About Controlling AI, We Must Learn How to Trace Decisions**  
    Argues that control is meaningless without causal traceability of decisions.
4. **When AI Actions Cannot Be Traced, Governance Becomes an Illusion**  
    Demonstrates why governance collapses when actions lack causal accountability.
5. **When Governance Only Audits Outcomes, Risk Has Already Accumulated**  
    Explains why outcome-based governance is structurally late and risk-blind.

---

## How This Series Is Intended to Be Read

The articles are ordered to progressively build the argument:

- from the **limits of prompt-based engineering**,
- through **responsibility displacement**,
- toward **traceability and governance failure**.

This series does not propose solutions.  
It defines the **governance failure surface** that future methodologies must address.

Each article can be read independently, but the series is designed to be read in order,
as each piece builds upon the structural failures identified in the previous one.
